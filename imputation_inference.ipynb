{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Specified object-type columns successfully converted to 0 and 1.\n",
      "PRIMARY_RACE_American Indian / Native American     int64\n",
      "PRIMARY_RACE_Asian                                 int64\n",
      "PRIMARY_RACE_Asian Indian                          int64\n",
      "PRIMARY_RACE_Black / African American              int64\n",
      "PRIMARY_RACE_Middle Eastern                        int64\n",
      "PRIMARY_RACE_Native Hawaiian / Pacific Islander    int64\n",
      "PRIMARY_RACE_White                                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_encoded = pd.read_pickle(\"df_encoded_files/df_encoded.pkl\")\n",
    "\n",
    "# Convert boolean data types to integers\n",
    "df_encoded = df_encoded.astype({col: int for col in df_encoded.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "race_columns = [col for col in df_encoded.columns if col.startswith(\"PRIMARY_RACE\") and col != \"PRIMARY_RACE_Unknown\"]\n",
    "df_encoded.loc[df_encoded[race_columns].sum(axis=1) == 0, \"PRIMARY_RACE_Unknown\"] = 1\n",
    "unknown_ethnicity_list = []\n",
    "\n",
    "filtered_rows = df_encoded[df_encoded['PRIMARY_ETHNICITY_Unknown'] == 1]\n",
    "\n",
    "i = 0\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    unknown_ethnicity_list.append(index)\n",
    "\n",
    "\n",
    "unknown_race_list = []\n",
    "\n",
    "filtered_rows = df_encoded[df_encoded['PRIMARY_RACE_Unknown'] == 1]\n",
    "\n",
    "i = 0\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    unknown_race_list.append(index)\n",
    "\n",
    "# List of columns that need to be converted\n",
    "columns_to_convert = [\n",
    "    'PRIMARY_RACE_American Indian / Native American',\n",
    "    'PRIMARY_RACE_Asian',\n",
    "    'PRIMARY_RACE_Asian Indian',\n",
    "    'PRIMARY_RACE_Black / African American',\n",
    "    'PRIMARY_RACE_Middle Eastern',\n",
    "    'PRIMARY_RACE_Native Hawaiian / Pacific Islander',\n",
    "    'PRIMARY_RACE_White'\n",
    "]\n",
    "\n",
    "existing_columns = [col for col in columns_to_convert if col in df_encoded.columns]\n",
    "\n",
    "df_encoded[existing_columns] = df_encoded[existing_columns].apply(\n",
    "    lambda col: col.astype(str).str.lower().map({'false': 0, 'true': 1}).fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "print(\"âœ… Specified object-type columns successfully converted to 0 and 1.\")\n",
    "print(df_encoded[existing_columns].dtypes) \n",
    "\n",
    "df_encoded[\"RPL_THEME1\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Define the columns to impute\n",
    "columns_to_impute = [\n",
    "    \"min_BMI\", \"min_HEIGHT\", \"min_PULSE\", \"min_WEIGHT\",\n",
    "    \"max_BMI\", \"max_HEIGHT\", \"max_PULSE\", \"max_WEIGHT\",\n",
    "    \"mean_BMI\", \"mean_HEIGHT\", \"mean_PULSE\", \"mean_WEIGHT\",\n",
    "    \"SYSTOLIC_BP_min\", \"SYSTOLIC_BP_max\", \"SYSTOLIC_BP_mean\",\n",
    "    \"DIASTOLIC_BP_min\", \"DIASTOLIC_BP_max\", \"DIASTOLIC_BP_mean\"\n",
    "]\n",
    "\n",
    "df_knn_impute = df_encoded.copy()\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn_impute[columns_to_impute] = knn_imputer.fit_transform(df_knn_impute[columns_to_impute])\n",
    "df_encoded[columns_to_impute] = df_encoded[columns_to_impute].where(df_encoded.notna(), df_knn_impute[columns_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "class INA_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(INA_Autoencoder, self).__init__()\n",
    "\n",
    "        # Undercomplete Representation: Smaller hidden layers than input\n",
    "        hidden_dim1 = int(input_dim * 0.75)  \n",
    "        hidden_dim2 = int(input_dim * 0.60)\n",
    "        hidden_dim3 = int(input_dim * 0.5)   \n",
    "        \n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim3, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim1, input_dim),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in input\")\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        if torch.isnan(encoded).any():\n",
    "            print(\"NaN detected in encoding\")\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        if torch.isnan(decoded).any():\n",
    "            print(\"NaN detected in output\")\n",
    "        \n",
    "        return decoded\n",
    "\n",
    "\n",
    "# Define the columns to remove before imputation\n",
    "unknown_columns = [\n",
    "    'PRIMARY_ETHNICITY_Unknown',\n",
    "    'PRIMARY_RACE_Unknown',\n",
    "    'LANGUAGE_Unknown',\n",
    "    'D_Insur_at_pull_Unknown',\n",
    "]\n",
    "\n",
    "df_impute = df_encoded.drop(columns=unknown_columns, errors='ignore').copy()\n",
    "df_impute = df_impute.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "\n",
    "# ðŸ”¹ Load the trained I-NAA model\n",
    "model_path = \"best_inaa_models/best_INAA_MAR_30.pth\"\n",
    "\n",
    "\n",
    "# Initialize the model with the correct input size (based on df_impute)\n",
    "input_dim = df_impute.shape[1]\n",
    "model = INA_Autoencoder(input_dim)  # Ensure the model matches feature count\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "missing_rows = (df_encoded['RPL_THEME1'] == 0) | df_encoded['RPL_THEME1'].isna()\n",
    "input_data = torch.tensor(df_impute.loc[missing_rows].values, dtype=torch.float32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    imputed_data = model(input_data).cpu().numpy()  # Move back to CPU\n",
    "\n",
    "df_impute.loc[missing_rows, df_impute.columns] = imputed_data\n",
    "\n",
    "print(\"Imputation complete! _Unknown columns are preserved.\")\n",
    "\n",
    "df_encoded.loc[missing_rows, \"RPL_THEME1\"] = df_impute.loc[missing_rows, \"RPL_THEME1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_pickle(\"df_encoded_imputed_final.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
