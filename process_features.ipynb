{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:277: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_labs[\"RESULT_VALUE_NUM\"] = pd.to_numeric(filtered_labs[\"RESULT_VALUE_NUM\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  demo_age  RPL_THEME1  GENDER_F  GENDER_M  GENDER_U  \\\n",
      "0  10000        49        0.49      True     False     False   \n",
      "1  10001        67        0.75      True     False     False   \n",
      "2  10002        80        0.79      True     False     False   \n",
      "3  10004        83        0.55      True     False     False   \n",
      "4  10005        82        0.66     False      True     False   \n",
      "\n",
      "  PRIMARY_RACE_American Indian / Native American PRIMARY_RACE_Asian  \\\n",
      "0                                          False              False   \n",
      "1                                          False              False   \n",
      "2                                          False              False   \n",
      "3                                          False              False   \n",
      "4                                          False              False   \n",
      "\n",
      "  PRIMARY_RACE_Asian Indian PRIMARY_RACE_Black / African American  ...  \\\n",
      "0                     False                                     1  ...   \n",
      "1                     False                                 False  ...   \n",
      "2                     False                                     1  ...   \n",
      "3                     False                                  True  ...   \n",
      "4                     False                                     1  ...   \n",
      "\n",
      "   F12.20 F43.21 F19.20  F20.3  F10.11 F41.8  F41.0  F33.2  F20.89  F34.1  \n",
      "0       0      0      0      0       0     0      0      0       0      0  \n",
      "1       0      0      0      0       0     0      0      0       0      0  \n",
      "2       0      0      0      0       0     0      0      0       0      0  \n",
      "3       0      0      0      0       0     0      0      0       0      0  \n",
      "4       0      0      0      0       0     0      0      0       0      0  \n",
      "\n",
      "[5 rows x 168 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:333: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['PRIMARY_RACE_Chinese'] == 1, 'PRIMARY_RACE_Asian'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:336: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['PRIMARY_RACE_Native Hawaiian / Other Pacific Islander'] == 1, 'PRIMARY_RACE_Native Hawaiian / Pacific Islander'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:340: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['PRIMARY_RACE_American Indian or Alaskan Native'] == 1, 'PRIMARY_RACE_American Indian / Native American'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:343: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['PRIMARY_ETHNICITY_Middle Eastern'] == 1, 'PRIMARY_RACE_Middle Eastern'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:346: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[['PRIMARY_ETHNICITY_Russian', 'PRIMARY_ETHNICITY_American', 'PRIMARY_ETHNICITY_European']].sum(axis=1) > 0, 'PRIMARY_RACE_White'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:349: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['PRIMARY_ETHNICITY_Asian Indian'] == 1, 'PRIMARY_RACE_Asian Indian'] = 1\n",
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\4107370961.py:352: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[['PRIMARY_ETHNICITY_African', 'PRIMARY_ETHNICITY_African American', 'PRIMARY_ETHNICITY_Cape Verdean', 'PRIMARY_ETHNICITY_Caribbean Islander', 'PRIMARY_ETHNICITY_Haitian', 'PRIMARY_ETHNICITY_Middle Eastern or North African']].sum(axis=1) > 0, 'PRIMARY_RACE_Black / African American'] = 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "# Function to extract numeric dose values from strings like \"10 MG\"\n",
    "def extract_numeric_dose(dose):\n",
    "    if isinstance(dose, str):\n",
    "        match = re.search(r\"[\\d]+(?:\\.\\d+)?\", dose)  \n",
    "        return float(match.group()) if match else None\n",
    "    return dose \n",
    "\n",
    "# Map full medication names back to their generic form (CLOZAPINE, RISPERIDONE, OLANZAPINE)\n",
    "def get_medication_generic_name(med_name):\n",
    "    for med in medications:\n",
    "        if med in med_name:\n",
    "            return med\n",
    "    return None\n",
    "\n",
    "# Function to check if any vital keyword is in \"FLO_DISPLAY_NM\"\n",
    "def contains_vital(vital_name, target_list):\n",
    "    return any(target in vital_name for target in target_list)\n",
    "\n",
    "# Function to extract numeric values from vitals data\n",
    "def extract_numeric_value(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.search(r\"[\\d]+(?:\\.\\d+)?\", value)  # Extract number including decimals\n",
    "        return float(match.group()) if match else None\n",
    "    return value  # If already a number, return as is\n",
    "\n",
    "# Map full FLO_DISPLAY_NM names back to generic names (HEIGHT, WEIGHT, BMI)\n",
    "def get_vital_name(display_name):\n",
    "    for vital in vitals:\n",
    "        if vital in display_name:\n",
    "            return vital\n",
    "    return None\n",
    "\n",
    "\n",
    "file_name = \"data/S001_u7.5.2024_DI_from_3.2024_Merged_Demo_Geo_by_Tithi.xlsx\"\n",
    "\n",
    "columns_to_use = [\n",
    "    'ID', \n",
    "    'GENDER', \n",
    "    'demo_age', \n",
    "    'PRIMARY_RACE', \n",
    "    'LANGUAGE', \n",
    "    'PRIMARY_ETHNICITY', \n",
    "    'D_Insur_at_pull', \n",
    "    'RPL_THEME1'\n",
    "]\n",
    "\n",
    "df = pd.read_excel(file_name, usecols=columns_to_use)\n",
    "\n",
    "\n",
    "df['PRIMARY_RACE'] = df['PRIMARY_RACE'].replace(\n",
    "    [\"Declined / Not Available\", \"Choose not to Answer\", \"Unknown\", ''],\n",
    "    'Unknown'\n",
    ")\n",
    "\n",
    "df['LANGUAGE'] = df['LANGUAGE'].fillna('Unknown')\n",
    "df['LANGUAGE'] = df['LANGUAGE'].replace(r'^\\s*$', 'Unknown', regex=True)\n",
    "\n",
    "df['PRIMARY_ETHNICITY'] = df['PRIMARY_ETHNICITY'].replace(\n",
    "    [\"Patient Refused\", \"Patient chooses not to answer\", \"Unknown/Not Specified\",\"\"],\n",
    "    'Unknown'\n",
    ")\n",
    "\n",
    "df['D_Insur_at_pull'] = df['D_Insur_at_pull'].fillna('Unknown')\n",
    "df['D_Insur_at_pull'] = df['D_Insur_at_pull'].replace(r'^\\s*$', 'Unknown', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "categorical_columns = ['GENDER', 'PRIMARY_RACE', 'LANGUAGE', 'PRIMARY_ETHNICITY', 'D_Insur_at_pull']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "df_encoded[\"RPL_THEME1\"] = pd.to_numeric(df_encoded[\"RPL_THEME1\"], errors=\"coerce\")  # Convert non-numeric to NaN\n",
    "df_encoded.loc[(df_encoded[\"RPL_THEME1\"] < 0) | (df_encoded[\"RPL_THEME1\"] > 1), \"RPL_THEME1\"] = np.nan  # Replace invalid values\n",
    "\n",
    "\n",
    "# Load the Excel spreadsheet\n",
    "data_path = \"data/anonymized_H-43413 Qualifying Encounters.xlsx\"\n",
    "df_icd10 = pd.read_excel(data_path)\n",
    "\n",
    "icd10_codes = ['F28', 'F20.5', 'F20.2', 'F21', 'F23', 'F24', 'F20.81', 'F25.8', 'F20.1']\n",
    "\n",
    "df_icd10_binary = df_icd10.pivot_table(index='ID', columns='ICD-10', aggfunc='size', fill_value=0)\n",
    "df_icd10_binary = df_icd10_binary.reindex(columns=icd10_codes, fill_value=0)\n",
    "df_icd10_binary.reset_index(inplace=True)\n",
    "df_encoded = df_encoded.merge(df_icd10_binary, on=\"ID\", how=\"left\")\n",
    "df_encoded.fillna(0, inplace=True)\n",
    "df_encoded[icd10_codes] = (df_encoded[icd10_codes] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"data/anonymized_H-43413 Amb Med Data.xlsx\"\n",
    "df_med = pd.read_excel(file_path)\n",
    "\n",
    "medications = [\"CLOZAPINE\", \"RISPERIDONE\", \"OLANZAPINE\"]\n",
    "df_med[\"MEDICATION NAME\"] = df_med[\"MEDICATION NAME\"].str.upper()\n",
    "def contains_medication(med_name, target_list):\n",
    "    return any(target in med_name for target in target_list)\n",
    "df_filtered = df_med[df_med[\"MEDICATION NAME\"].apply(lambda x: contains_medication(x, medications))].copy()\n",
    "\n",
    "\n",
    "df_filtered[\"DOSE\"] = df_filtered[\"DOSE\"].apply(extract_numeric_dose)\n",
    "df_filtered = df_filtered.dropna(subset=[\"DOSE\"])\n",
    "df_filtered[\"DOSE\"] = df_filtered[\"DOSE\"].astype(float)\n",
    "\n",
    "\n",
    "df_filtered[\"GENERIC_MED_NAME\"] = df_filtered[\"MEDICATION NAME\"].apply(get_medication_generic_name)\n",
    "\n",
    "df_stats = df_filtered.groupby([\"ID\", \"GENERIC_MED_NAME\"])[\"DOSE\"].agg([\"min\", \"max\", \"mean\"]).reset_index()\n",
    "\n",
    "# Pivot table to create separate columns for each medication and statistic\n",
    "df_pivot = df_stats.pivot(index=\"ID\", columns=\"GENERIC_MED_NAME\", values=[\"min\", \"max\", \"mean\"])\n",
    "\n",
    "df_pivot.columns = [f\"{stat}_{med}\" for stat, med in df_pivot.columns]\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "for med in medications:\n",
    "    for stat in [\"min\", \"max\", \"mean\"]:\n",
    "        col_name = f\"{stat}_{med}\"\n",
    "        if col_name not in df_pivot.columns:\n",
    "            df_pivot[col_name] = 0  \n",
    "\n",
    "df_encoded = df_encoded.merge(df_pivot, on=\"ID\", how=\"left\")\n",
    "\n",
    "# Replace NaN values in the 9 medication-related columns with 0\n",
    "for med in medications:\n",
    "    for stat in [\"min\", \"max\", \"mean\"]:\n",
    "        col_name = f\"{stat}_{med}\"\n",
    "        df_encoded[col_name] = df_encoded[col_name].fillna(0)\n",
    "\n",
    "# Load the vitals CSV file\n",
    "vitals_file_path = \"data/anonymized_H43413_vitals.csv\"\n",
    "df_vitals = pd.read_csv(vitals_file_path)\n",
    "df_vitals[\"FLO_DISPLAY_NM\"] = df_vitals[\"FLO_DISPLAY_NM\"].str.upper()\n",
    "vitals = [\"HEIGHT\", \"WEIGHT\", \"BMI\", \"PULSE\"]\n",
    "\n",
    "df_filtered = df_vitals[df_vitals[\"FLO_DISPLAY_NM\"].apply(lambda x: contains_vital(x, vitals))].copy()\n",
    "df_filtered[\"ENTERED_VALUE\"] = df_filtered[\"ENTERED_VALUE\"].apply(extract_numeric_value)\n",
    "df_filtered = df_filtered.dropna(subset=[\"ENTERED_VALUE\"])\n",
    "df_filtered[\"ENTERED_VALUE\"] = df_filtered[\"ENTERED_VALUE\"].astype(float)\n",
    "df_filtered[\"VITAL_NAME\"] = df_filtered[\"FLO_DISPLAY_NM\"].apply(get_vital_name)\n",
    "\n",
    "df_stats = df_filtered.groupby([\"ID\", \"VITAL_NAME\"])[\"ENTERED_VALUE\"].agg([\"min\", \"max\", \"mean\"]).reset_index()\n",
    "\n",
    "df_pivot = df_stats.pivot(index=\"ID\", columns=\"VITAL_NAME\", values=[\"min\", \"max\", \"mean\"])\n",
    "df_pivot.columns = [f\"{stat}_{vital}\" for stat, vital in df_pivot.columns]\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Ensure all vital-related variables exist in df_encoded, even if missing in df_pivot\n",
    "for vital in vitals:\n",
    "    for stat in [\"min\", \"max\", \"mean\"]:\n",
    "        col_name = f\"{stat}_{vital}\"\n",
    "        if col_name not in df_pivot.columns:\n",
    "            df_pivot[col_name] = 0  # Fill missing columns with 0\n",
    "\n",
    "# Merge with df_encoded\n",
    "df_encoded = df_encoded.merge(df_pivot, on=\"ID\", how=\"left\")\n",
    "\n",
    "# Replace NaN values in the new columns with 0\n",
    "for vital in vitals:\n",
    "    for stat in [\"min\", \"max\", \"mean\"]:\n",
    "        col_name = f\"{stat}_{vital}\"\n",
    "        df_encoded[col_name] = df_encoded[col_name].fillna(0)\n",
    "\n",
    "\n",
    "# Load the anonymized blood pressure data\n",
    "bp_df = pd.read_csv(\"data/anonymized_H43413_bp.csv\")\n",
    "\n",
    "bp_df['ID'] = bp_df['ID'].astype(str)\n",
    "df_encoded['ID'] = df_encoded['ID'].astype(str)\n",
    "\n",
    "# Compute blood pressure statistics for each patient\n",
    "bp_stats = bp_df.groupby('ID').agg({\n",
    "    'SYSTOLIC_BP': ['min', 'max', 'mean'],\n",
    "    'DIASTOLIC_BP': ['min', 'max', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "bp_stats.columns = ['ID', 'SYSTOLIC_BP_min', 'SYSTOLIC_BP_max', 'SYSTOLIC_BP_mean',\n",
    "                    'DIASTOLIC_BP_min', 'DIASTOLIC_BP_max', 'DIASTOLIC_BP_mean']\n",
    "\n",
    "df_encoded = df_encoded.merge(bp_stats, on='ID', how='left')\n",
    "\n",
    "\n",
    "# lab test data\n",
    "lab_data_path = \"data/anonymized_h43413_labs.csv\"\n",
    "lab_data = pd.read_csv(lab_data_path)\n",
    "\n",
    "lab_tests = [\"CREATININE\", \"BMC_GLUCOSE\", \"BMC_ALT(SGPT)\", \"BMC_AST(SGOT)\"]\n",
    "\n",
    "filtered_labs = lab_data[lab_data[\"RESULT_TEST_NM\"].isin(lab_tests)]\n",
    "filtered_labs[\"RESULT_VALUE_NUM\"] = pd.to_numeric(filtered_labs[\"RESULT_VALUE_NUM\"], errors=\"coerce\")\n",
    "\n",
    "patient_ids = df_encoded[\"ID\"].unique()\n",
    "\n",
    "filtered_labs = filtered_labs[filtered_labs[\"ID\"].isin(patient_ids)]\n",
    "\n",
    "lab_summary = (\n",
    "    filtered_labs.groupby([\"ID\", \"RESULT_TEST_NM\"])[\"RESULT_VALUE_NUM\"]\n",
    "    .agg([\"min\", \"max\", \"mean\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "lab_summary = lab_summary.pivot(index=\"ID\", columns=\"RESULT_TEST_NM\", values=[\"min\", \"max\", \"mean\"])\n",
    "\n",
    "lab_summary.columns = [f\"{stat}_{test}\" for stat, test in lab_summary.columns]\n",
    "lab_summary.reset_index(inplace=True)\n",
    "\n",
    "df_encoded = df_encoded.merge(lab_summary, on=\"ID\", how=\"left\")\n",
    "\n",
    "\n",
    "# Problem list\n",
    "problem_list_df = pd.read_excel(\"data/anonymized_H-43413 Data Add On.xlsx\", sheet_name=\"Problem List\")\n",
    "\n",
    "problem_list_df['ID'] = problem_list_df['ID'].astype(str)\n",
    "df_encoded['ID'] = df_encoded['ID'].astype(str)\n",
    "\n",
    "# List of ICD-10 codes to check\n",
    "icd10_codes = [\n",
    "    \"F17.200\", \"F20.9\", \"F39\", \"F25.9\", \"F43.10\", \"F29\", \"F32.A\", \"F41.1\", \"F41.9\", \"F11.20\", \"F31.9\", \"F22\", \n",
    "    \"F25.0\", \"F20.0\", \"F33.1\", \"F19.10\", \"F10.20\", \"F10.10\", \"F43.20\", \"F14.10\", \"F32.9\", \"F17.210\", \"F14.20\", \n",
    "    \"F99\", \"F25.1\", \"F12.10\", \"F19.90\", \"F90.9\", \"F33.9\", \"F11.21\", \"F33.3\", \"F10.21\", \"F11.90\", \"F12.20\", \n",
    "    \"F43.21\", \"F19.20\", \"F20.3\", \"F10.11\", \"F41.8\", \"F41.0\", \"F33.2\", \"F20.89\", \"F34.1\"\n",
    "]\n",
    "\n",
    "df_encoded[icd10_codes] = 0\n",
    "\n",
    "for index, row in problem_list_df.iterrows():\n",
    "    patient_id = row['ID']\n",
    "    icd_list = str(row['CURRENT ICD-10 LIST']).split(', ')\n",
    "    \n",
    "    if patient_id in df_encoded['ID'].values:\n",
    "        for icd_code in icd10_codes:\n",
    "            if icd_code in icd_list:\n",
    "                df_encoded.loc[df_encoded['ID'] == patient_id, icd_code] = 1\n",
    "\n",
    "def update_primary_race(df):\n",
    "    # Process values for race and ethinicity\n",
    "    df.loc[df['PRIMARY_RACE_Chinese'] == 1, 'PRIMARY_RACE_Asian'] = 1\n",
    "    \n",
    "    df.loc[df['PRIMARY_RACE_Native Hawaiian / Other Pacific Islander'] == 1, 'PRIMARY_RACE_Native Hawaiian / Pacific Islander'] = 1\n",
    "\n",
    "    df.loc[df['PRIMARY_RACE_Other Pacific Islander'] == 1, 'PRIMARY_RACE_Native Hawaiian / Pacific Islander'] = 1\n",
    "    \n",
    "    df.loc[df['PRIMARY_RACE_American Indian or Alaskan Native'] == 1, 'PRIMARY_RACE_American Indian / Native American'] = 1\n",
    "    \n",
    "    df.loc[df['PRIMARY_ETHNICITY_Middle Eastern'] == 1, 'PRIMARY_RACE_Middle Eastern'] = 1\n",
    "    \n",
    "    df.loc[df[['PRIMARY_ETHNICITY_Russian', 'PRIMARY_ETHNICITY_American', 'PRIMARY_ETHNICITY_European']].sum(axis=1) > 0, 'PRIMARY_RACE_White'] = 1\n",
    "    \n",
    "    df.loc[df['PRIMARY_ETHNICITY_Asian Indian'] == 1, 'PRIMARY_RACE_Asian Indian'] = 1\n",
    "    \n",
    "    df.loc[df[['PRIMARY_ETHNICITY_African', 'PRIMARY_ETHNICITY_African American', 'PRIMARY_ETHNICITY_Cape Verdean', 'PRIMARY_ETHNICITY_Caribbean Islander', 'PRIMARY_ETHNICITY_Haitian', 'PRIMARY_ETHNICITY_Middle Eastern or North African']].sum(axis=1) > 0, 'PRIMARY_RACE_Black / African American'] = 1\n",
    "    \n",
    "    df.loc[df[['PRIMARY_ETHNICITY_Cambodian', 'PRIMARY_ETHNICITY_Chinese', 'PRIMARY_ETHNICITY_Filipino', 'PRIMARY_ETHNICITY_Japanese', 'PRIMARY_ETHNICITY_Korean', 'PRIMARY_ETHNICITY_Laotian', 'PRIMARY_ETHNICITY_Vietnamese']].sum(axis=1) > 0, 'PRIMARY_RACE_Asian'] = 1\n",
    "    \n",
    "    race_columns = [col for col in df.columns if col.startswith('PRIMARY_RACE_') and col != 'PRIMARY_RACE_Unknown']\n",
    "    df['PRIMARY_RACE_Unknown'] = (df[race_columns].sum(axis=1) == 0).astype(int)\n",
    "    \n",
    "    ethnicity_columns = [col for col in df.columns if col.startswith('PRIMARY_ETHNICITY_') and col != 'PRIMARY_ETHNICITY_Unknown']\n",
    "    df['PRIMARY_ETHNICITY_Unknown'] = (df[ethnicity_columns].sum(axis=1) == 0).astype(int)\n",
    "    \n",
    "    # Drop the specified columns\n",
    "    df.drop(columns=['PRIMARY_RACE_Chinese', 'PRIMARY_RACE_Other Pacific Islander', 'PRIMARY_RACE_Native Hawaiian / Other Pacific Islander', 'PRIMARY_RACE_American Indian or Alaskan Native'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_encoded = update_primary_race(df_encoded)\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khang\\AppData\\Local\\Temp\\ipykernel_15100\\3294417873.py:47: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_encoded = df_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get valid IDs from a spreadsheet\n",
    "def get_valid_ids(file_path):\n",
    "    try:\n",
    "        \n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, usecols=['ID'])  # Load only ID column\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, usecols=['ID'])  # Load only ID column\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            \n",
    "            return set()\n",
    "        # Load spreadsheet (CSV or Excel)\n",
    "        if file_path ==  \"data/anonymized_H-43413 Data Add On.xlsx\":\n",
    "            df = pd.read_excel(\"data/anonymized_H-43413 Data Add On.xlsx\", sheet_name=\"Problem List\", usecols=['ID'])\n",
    "        \n",
    "\n",
    "        return set(df['ID'].dropna().astype(str))  # Convert to string and remove NaNs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return set()\n",
    "    \n",
    "# File paths\n",
    "file_paths = [\n",
    "    \"data/anonymized_H-43413 Amb Med Data.xlsx\",\n",
    "    \"data/anonymized_H43413_vitals.csv\",\n",
    "    \"data/anonymized_H-43413 Qualifying Encounters.xlsx\",\n",
    "    \"data/anonymized_h43413_labs.csv\",\n",
    "    \"data/anonymized_H-43413 Data Add On.xlsx\",\n",
    "    \"data/anonymized_H43413_bp.csv\"\n",
    "]\n",
    "\n",
    "df_encoded_ids = set(df_encoded['ID'].astype(str)) \n",
    "\n",
    "valid_ids = df_encoded_ids \n",
    "for file in file_paths:\n",
    "    valid_ids &= get_valid_ids(file) \n",
    "df_encoded = df_encoded[df_encoded['ID'].astype(str).isin(valid_ids)]\n",
    "\n",
    "df_encoded = df_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_pickle(\"df_encoded.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
